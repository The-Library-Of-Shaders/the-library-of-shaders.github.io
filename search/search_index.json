{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the Library of Shaders The Library of Shaders is an open-source project that intends to release copyright and license free examples and explanations of miscellaneous shader effects, in order to empower developers to learn and develop shader effects themselves. All shader code here is written in valid GLSL or OpenGL Shading Language . Variables We define a few variables that match the ShaderToy environment for ease of testing, but they can be easily adapted if you use another shader language (e.g. Godot's shader language) as needed. // ShaderToy uniforms uniform vec3 iResolution; // viewport resolution (in pixels) uniform float iTime; // shader playback time (in seconds) uniform float iTimeDelta; // render time (in seconds) uniform float iFrameRate; // shader frame rate uniform int iFrame; // shader playback frame uniform float iChannelTime[4]; // channel playback time (in seconds) uniform vec3 iChannelResolution[4]; // channel resolution (in pixels) uniform vec4 iMouse; // mouse pixel coords. xy: current (if MLB down), zw: click uniform samplerXX iChannel0..3; // input channel. XX = 2D/Cube uniform vec4 iDate; // (year, month, day, time in seconds) If ShaderToy does not have a uniform for a certain thing that the shader requires, it will be explained in the article, and the uniforms will still follow the naming convention for ShaderToy. An example of this is vertex shaders . Because ShaderToy is mainly a playground for fragment shaders , there's nothing like uniform mat4 iModel; . However, we still have a section for vertex shaders, they just won't be able to run in the ShaderToy environment. Articles will explain any uniforms not available in ShaderToy. Contributing All contributions are welcomed, and the contribution guide can be viewed on the GitHub repository . This library is built by developers for developers, and we appreciate everyone's help. We strive to follow the principals of the 5 Wikipedian Pillars . Licensing and Copyright This entire library, and all work inside of it, is licensed under Creative Commons Zero . You can read the full text here .","title":"Home"},{"location":"#welcome-to-the-library-of-shaders","text":"The Library of Shaders is an open-source project that intends to release copyright and license free examples and explanations of miscellaneous shader effects, in order to empower developers to learn and develop shader effects themselves. All shader code here is written in valid GLSL or OpenGL Shading Language .","title":"Welcome to the Library of Shaders"},{"location":"#variables","text":"We define a few variables that match the ShaderToy environment for ease of testing, but they can be easily adapted if you use another shader language (e.g. Godot's shader language) as needed. // ShaderToy uniforms uniform vec3 iResolution; // viewport resolution (in pixels) uniform float iTime; // shader playback time (in seconds) uniform float iTimeDelta; // render time (in seconds) uniform float iFrameRate; // shader frame rate uniform int iFrame; // shader playback frame uniform float iChannelTime[4]; // channel playback time (in seconds) uniform vec3 iChannelResolution[4]; // channel resolution (in pixels) uniform vec4 iMouse; // mouse pixel coords. xy: current (if MLB down), zw: click uniform samplerXX iChannel0..3; // input channel. XX = 2D/Cube uniform vec4 iDate; // (year, month, day, time in seconds) If ShaderToy does not have a uniform for a certain thing that the shader requires, it will be explained in the article, and the uniforms will still follow the naming convention for ShaderToy. An example of this is vertex shaders . Because ShaderToy is mainly a playground for fragment shaders , there's nothing like uniform mat4 iModel; . However, we still have a section for vertex shaders, they just won't be able to run in the ShaderToy environment. Articles will explain any uniforms not available in ShaderToy.","title":"Variables"},{"location":"#contributing","text":"All contributions are welcomed, and the contribution guide can be viewed on the GitHub repository . This library is built by developers for developers, and we appreciate everyone's help. We strive to follow the principals of the 5 Wikipedian Pillars .","title":"Contributing"},{"location":"#licensing-and-copyright","text":"This entire library, and all work inside of it, is licensed under Creative Commons Zero . You can read the full text here .","title":"Licensing and Copyright"},{"location":"Fragment/","text":"Fragment Shaders Fragment shaders are the shaders that run directly on geometry, usually after vertex shaders. They can do a lot of things, such as texturing, fog, and normal map effects.","title":"Index"},{"location":"Fragment/#fragment-shaders","text":"Fragment shaders are the shaders that run directly on geometry, usually after vertex shaders. They can do a lot of things, such as texturing, fog, and normal map effects.","title":"Fragment Shaders"},{"location":"PostProcessing/","text":"Post-Processing Shaders Post-processing shaders are exactly what they sound like. These shaders run after (post-) initial processing happens. Instead of affecting how objects are drawn, they can apply final visual effects before the user sees the frame. Post-processing effects can include: Bloom Chromatic Aberration Motion Blur Sharpening Vignette and a lot of other very cool stuff.","title":"Index"},{"location":"PostProcessing/#post-processing-shaders","text":"Post-processing shaders are exactly what they sound like. These shaders run after (post-) initial processing happens. Instead of affecting how objects are drawn, they can apply final visual effects before the user sees the frame. Post-processing effects can include: Bloom Chromatic Aberration Motion Blur Sharpening Vignette and a lot of other very cool stuff.","title":"Post-Processing Shaders"},{"location":"PostProcessing/Bloom/","text":"Bloom // Coming soon","title":"Bloom"},{"location":"PostProcessing/Bloom/#bloom","text":"// Coming soon","title":"Bloom"},{"location":"PostProcessing/ChromaticAberration/","text":"Chromatic Aberration Chromatic Aberration is an effect commonly observed in images, when the camera can't focus all color channels onto a point. This results in different colors being in slightly different positions. In shaders, this effect can be simulated by offsetting the position at which we sample each color channel. This is quite simple, but the value by which you offset needs to be quite small in order to look any good. Let's first assume a couple variables we have access to. fragCoord iResolution These are explained on the home page, under variables. Let's grab the normalized coordinates of our pixel. Since fragCoord ranges from 0 to the screen dimensions, we just need to divide by the screen dimensions. vec2 normalizedCoords = fragCoord/iResolution.xy; Now let's define some small offsets. vec2 redOffset = vec2(0.001, 0.002); vec2 greenOffset = vec2(-0.002, 0.001); vec2 blueOffset = vec2(0.003, 0.002); Now that we have some offsets, we can just sample our texture with them. Assuming we have a texture sampler called iChannel0 : float red = texture(iChannel0, normalizedCoords + redOffset).r; float green = texture(iChannel0, normalizedCoords + greenOffset).g; vec2 blueAlpha = texture(iChannel0, normalizedCoords + blueOffset).ba; Using swizzling , or accessing only a specific component of a vector, we can easily get only the value we need. Notice that for the last channel, I use a vec2 instead of a float, because, of course, we need to get the alpha channel as well. We'll just use the blue offset to sample the alpha channel. Now, we can join it all together. fragColor = vec4(red, green, blueAlpha); Edge Strengthening So, we've constructed our output color with the offset channels. This is oftentimes enough, but realistically, you'll only see chromatic aberration near the very edges of images, and not so much at the center. To make this effect more realistic, we can simulate that. We have the current normalized position in normalizedCoords . At the moment this ranges from 0 to 1, but with a bit of clever math we can get something cool. First, let's shift our coordinates over. vec2 shiftedCoords = normalizedCoords - 0.5; So now, the coordinates range from -0.5 to 0.5. We're close now, we just need to take the absolute value of the coordinates to get rid of that negative. shiftedCoords = abs(shiftedCoords); Now, let's edit our previous texture sampling code. float red = texture(iChannel0, normalizedCoords + (shiftedCoords * redOffset)).r; float green = texture(iChannel0, normalizedCoords + (shiftedCoords * greenOffset)).g; vec2 blueAlpha = texture(iChannel0, normalizedCoords + (shiftedCoords * blueOffset)).ba; So, you see, the values range from 0.5 at the bottom left, to 0.5 at the top right. This means that in the center, the values are 0.0, or around it. We're effectively reducing our offset by how close it is to the center. This means that the effect will only really be visible around the edges, which is exactly what we want. However, it's probably not going to be that visible, as we've effectively halved it, seeing as how we're multiplying by at most, 0.5. So, we can modify our absolute value line to increase it. shiftedCoords = abs(shiftedCoords) * 2.0; Doubling it brings it back to the original strength, but you can increase or decrease this however you want to tweak the strength. Full Program const float STRENGTH = 2.0; void mainImage( out vec4 fragColor, in vec2 fragCoord ) { vec2 normalizedCoords = fragCoord/iResolution.xy; vec2 redOffset = vec2(0.001, 0.002); vec2 greenOffset = vec2(-0.002, 0.001); vec2 blueOffset = vec2(0.003, 0.002); vec2 shiftedCoords = normalizedCoords - 0.5; shiftedCoords = abs(shiftedCoords) * STRENGTH; float red = texture(iChannel0, normalizedCoords + (shiftedCoords * redOffset)).r; float green = texture(iChannel0, normalizedCoords + (shiftedCoords * greenOffset)).g; vec2 blueAlpha = texture(iChannel0, normalizedCoords + (shiftedCoords * blueOffset)).ba; fragColor = vec4(red, green, blueAlpha); }","title":"Chromatic Aberration"},{"location":"PostProcessing/ChromaticAberration/#chromatic-aberration","text":"Chromatic Aberration is an effect commonly observed in images, when the camera can't focus all color channels onto a point. This results in different colors being in slightly different positions. In shaders, this effect can be simulated by offsetting the position at which we sample each color channel. This is quite simple, but the value by which you offset needs to be quite small in order to look any good. Let's first assume a couple variables we have access to. fragCoord iResolution These are explained on the home page, under variables. Let's grab the normalized coordinates of our pixel. Since fragCoord ranges from 0 to the screen dimensions, we just need to divide by the screen dimensions. vec2 normalizedCoords = fragCoord/iResolution.xy; Now let's define some small offsets. vec2 redOffset = vec2(0.001, 0.002); vec2 greenOffset = vec2(-0.002, 0.001); vec2 blueOffset = vec2(0.003, 0.002); Now that we have some offsets, we can just sample our texture with them. Assuming we have a texture sampler called iChannel0 : float red = texture(iChannel0, normalizedCoords + redOffset).r; float green = texture(iChannel0, normalizedCoords + greenOffset).g; vec2 blueAlpha = texture(iChannel0, normalizedCoords + blueOffset).ba; Using swizzling , or accessing only a specific component of a vector, we can easily get only the value we need. Notice that for the last channel, I use a vec2 instead of a float, because, of course, we need to get the alpha channel as well. We'll just use the blue offset to sample the alpha channel. Now, we can join it all together. fragColor = vec4(red, green, blueAlpha);","title":"Chromatic Aberration"},{"location":"PostProcessing/ChromaticAberration/#edge-strengthening","text":"So, we've constructed our output color with the offset channels. This is oftentimes enough, but realistically, you'll only see chromatic aberration near the very edges of images, and not so much at the center. To make this effect more realistic, we can simulate that. We have the current normalized position in normalizedCoords . At the moment this ranges from 0 to 1, but with a bit of clever math we can get something cool. First, let's shift our coordinates over. vec2 shiftedCoords = normalizedCoords - 0.5; So now, the coordinates range from -0.5 to 0.5. We're close now, we just need to take the absolute value of the coordinates to get rid of that negative. shiftedCoords = abs(shiftedCoords); Now, let's edit our previous texture sampling code. float red = texture(iChannel0, normalizedCoords + (shiftedCoords * redOffset)).r; float green = texture(iChannel0, normalizedCoords + (shiftedCoords * greenOffset)).g; vec2 blueAlpha = texture(iChannel0, normalizedCoords + (shiftedCoords * blueOffset)).ba; So, you see, the values range from 0.5 at the bottom left, to 0.5 at the top right. This means that in the center, the values are 0.0, or around it. We're effectively reducing our offset by how close it is to the center. This means that the effect will only really be visible around the edges, which is exactly what we want. However, it's probably not going to be that visible, as we've effectively halved it, seeing as how we're multiplying by at most, 0.5. So, we can modify our absolute value line to increase it. shiftedCoords = abs(shiftedCoords) * 2.0; Doubling it brings it back to the original strength, but you can increase or decrease this however you want to tweak the strength.","title":"Edge Strengthening"},{"location":"PostProcessing/ChromaticAberration/#full-program","text":"const float STRENGTH = 2.0; void mainImage( out vec4 fragColor, in vec2 fragCoord ) { vec2 normalizedCoords = fragCoord/iResolution.xy; vec2 redOffset = vec2(0.001, 0.002); vec2 greenOffset = vec2(-0.002, 0.001); vec2 blueOffset = vec2(0.003, 0.002); vec2 shiftedCoords = normalizedCoords - 0.5; shiftedCoords = abs(shiftedCoords) * STRENGTH; float red = texture(iChannel0, normalizedCoords + (shiftedCoords * redOffset)).r; float green = texture(iChannel0, normalizedCoords + (shiftedCoords * greenOffset)).g; vec2 blueAlpha = texture(iChannel0, normalizedCoords + (shiftedCoords * blueOffset)).ba; fragColor = vec4(red, green, blueAlpha); }","title":"Full Program"},{"location":"PostProcessing/GaussianBlur/","text":"Gaussian Blur // Coming soon","title":"Gaussian Blur"},{"location":"PostProcessing/GaussianBlur/#gaussian-blur","text":"// Coming soon","title":"Gaussian Blur"},{"location":"PostProcessing/Vignette/","text":"Vignette // Coming soon","title":"Vignette"},{"location":"PostProcessing/Vignette/#vignette","text":"// Coming soon","title":"Vignette"},{"location":"Resources/","text":"Resources This page provides a list of external resources for learning and extra enrichment. Godot Shader Docs Documentation for Godot's shader system ShaderToy Web-based fragment shader playground Iris Shader Docs Documentation for writing Minecraft shaderpacks using Iris The Book Of Shaders Step-by-step fragment shader guide, covers a lot of different things with great skill Inigo Quilez's Website Tons of masterful articles on various shader techniques","title":"Resources"},{"location":"Resources/#resources","text":"This page provides a list of external resources for learning and extra enrichment. Godot Shader Docs Documentation for Godot's shader system ShaderToy Web-based fragment shader playground Iris Shader Docs Documentation for writing Minecraft shaderpacks using Iris The Book Of Shaders Step-by-step fragment shader guide, covers a lot of different things with great skill Inigo Quilez's Website Tons of masterful articles on various shader techniques","title":"Resources"},{"location":"Vertex/","text":"Vertex Shaders Vertex shaders don't get a lot of recognition, but they are integral to how we see graphics, especially 3D graphics. Vertex shaders are responsible for running on vertices, or the points in our 3D model for example. They might handle converting world coordinates into screen-space coordinates, or perhaps procedural geometry deformation. They also pass a lot of data into fragment shaders, to enable them function properly (such as colors, or UVs).","title":"Index"},{"location":"Vertex/#vertex-shaders","text":"Vertex shaders don't get a lot of recognition, but they are integral to how we see graphics, especially 3D graphics. Vertex shaders are responsible for running on vertices, or the points in our 3D model for example. They might handle converting world coordinates into screen-space coordinates, or perhaps procedural geometry deformation. They also pass a lot of data into fragment shaders, to enable them function properly (such as colors, or UVs).","title":"Vertex Shaders"},{"location":"css/nobody/will/find/this/normally/cubester/","text":"Cubester Post this Cubester if Cubester","title":"Cubester"},{"location":"css/nobody/will/find/this/normally/cubester/#cubester","text":"Post this Cubester if Cubester","title":"Cubester"}]}