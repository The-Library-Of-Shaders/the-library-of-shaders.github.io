{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the Library of Shaders The Library of Shaders is an open-source project that intends to release copyright and license free examples and explanations for shader effects, in order to empower developers to learn and develop shader effects. All shader code is written to be valid GLSL or OpenGL Shading Language . We define a few variables which match the ShaderToy environment for ease of testing, but they can be swiftly adapted. Variables Shader Inputs uniform vec3 iResolution; // viewport resolution (in pixels) uniform float iTime; // shader playback time (in seconds) uniform float iTimeDelta; // render time (in seconds) uniform float iFrameRate; // shader frame rate uniform int iFrame; // shader playback frame uniform float iChannelTime[4]; // channel playback time (in seconds) uniform vec3 iChannelResolution[4]; // channel resolution (in pixels) uniform vec4 iMouse; // mouse pixel coords. xy: current (if MLB down), zw: click uniform samplerXX iChannel0..3; // input channel. XX = 2D/Cube uniform vec4 iDate; // (year, month, day, time in seconds) These are the uniforms defined by ShaderToy , and the shader examples in this library use them, as mentioned before, for ease of testing. Other shading langages, such as Godot's shader language, are quite similar to GLSL, and therefore easy to adapt these shaders to. Contributing All contributions are welcomed, and the contribution guide can be viewed on the github repository . This library is built by developers for developers, and we appreciate everyone's help. Licensing and Copyright This entire library and all work inside it is licensed Creative Commons Zero . You can do anything you want with it, including clone the entire website. The license information is avalible on the repository .","title":"Home"},{"location":"#welcome-to-the-library-of-shaders","text":"The Library of Shaders is an open-source project that intends to release copyright and license free examples and explanations for shader effects, in order to empower developers to learn and develop shader effects. All shader code is written to be valid GLSL or OpenGL Shading Language . We define a few variables which match the ShaderToy environment for ease of testing, but they can be swiftly adapted.","title":"Welcome to the Library of Shaders"},{"location":"#variables","text":"Shader Inputs uniform vec3 iResolution; // viewport resolution (in pixels) uniform float iTime; // shader playback time (in seconds) uniform float iTimeDelta; // render time (in seconds) uniform float iFrameRate; // shader frame rate uniform int iFrame; // shader playback frame uniform float iChannelTime[4]; // channel playback time (in seconds) uniform vec3 iChannelResolution[4]; // channel resolution (in pixels) uniform vec4 iMouse; // mouse pixel coords. xy: current (if MLB down), zw: click uniform samplerXX iChannel0..3; // input channel. XX = 2D/Cube uniform vec4 iDate; // (year, month, day, time in seconds) These are the uniforms defined by ShaderToy , and the shader examples in this library use them, as mentioned before, for ease of testing. Other shading langages, such as Godot's shader language, are quite similar to GLSL, and therefore easy to adapt these shaders to.","title":"Variables"},{"location":"#contributing","text":"All contributions are welcomed, and the contribution guide can be viewed on the github repository . This library is built by developers for developers, and we appreciate everyone's help.","title":"Contributing"},{"location":"#licensing-and-copyright","text":"This entire library and all work inside it is licensed Creative Commons Zero . You can do anything you want with it, including clone the entire website. The license information is avalible on the repository .","title":"Licensing and Copyright"},{"location":"articles/fragment/","text":"Fragment Shaders Fragment shaders are the shaders that run directly on geometry after vertex shaders usually. They can do a lot of things, such as texturing, fog, and normal map effects.","title":"Index"},{"location":"articles/fragment/#fragment-shaders","text":"Fragment shaders are the shaders that run directly on geometry after vertex shaders usually. They can do a lot of things, such as texturing, fog, and normal map effects.","title":"Fragment Shaders"},{"location":"articles/post/","text":"Post Processing Shaders Post processing shaders are, well, they are what they sound like. These shaders run after, or post, processing happens. Instead of affecting how objects are drawn, they can apply final visual effects, before the user sees the frame. Post processing effects can include: Bloom Motion Blur Sharpening Chromatic Aberration and a lot of other very cool stuff.","title":"Index"},{"location":"articles/post/#post-processing-shaders","text":"Post processing shaders are, well, they are what they sound like. These shaders run after, or post, processing happens. Instead of affecting how objects are drawn, they can apply final visual effects, before the user sees the frame. Post processing effects can include: Bloom Motion Blur Sharpening Chromatic Aberration and a lot of other very cool stuff.","title":"Post Processing Shaders"},{"location":"articles/post/Bloom/","text":"Bloom // Coming soon","title":"Bloom"},{"location":"articles/post/Bloom/#bloom","text":"// Coming soon","title":"Bloom"},{"location":"articles/post/ChromaticAberration/","text":"Chromatic Aberration Chromatic Aberration is an effect commonly observed in images, when the camera can't focus all color channels onto a point. This results in different colors being in slightly different positions. In shaders, this effect can be simulated by offsetting the position at which we sample each color channel. This is quite simple, but the value by which you offset needs to be quite small to look any good. Let's first assume a couple variables we have access to. fragCoord iResolution These are explained on the home page, under variables. Let's grab the normalized coordinates of our pixel. Since fragCoord ranges from 0 to the screen dimensions, we just need to divide by the screen dimensions. vec2 normalizedCoords = fragCoord/iResolution.xy; Now let's define some small offsets. vec2 redOffset = vec2(0.001, 0.002); vec2 greenOffset = vec2(-0.002, 0.001); vec2 blueOffset = vec2(0.003, 0.002); Now that we have some offsets, we can just sample our texture with them. Assuming we have a texture sampler called iChannel0 : float red = texture(iChannel0, normalizedCoords + redOffset).r; float green = texture(iChannel0, normalizedCoords + greenOffset).g; vec2 blueAlpha = texture(iChannel0, normalizedCoords + blueOffset).ba; Using swizzling , or accessing only a specific component of a vector, we can easily only get the value we need. Notice that for the last channel, I use a vector 2 instead of a float, because of course, we need to get the alpha channel as well. We'll just use the blue offset to sample the alpha channel. Now, we can join it all together. fragColor = vec4(red, green, blueAlpha); Edge Strengthing So, we've constructed our output color with the offset channels. This is often times enough, but realistically, you'll only see chromatic aberration near the very edges of images, and not so much the center. To make this effect more realistic, we can simulate that. We have the current normalized position in normalizedCoords . Now this ranges from 0 to 1, but with a bit of clever math we can get something cool. First, let's shift our coordinates over. vec2 shiftedCoords = normalizedCoords - 0.5; So now, the coordinates range from -0.5 to 0.5. We're close now, we just need to take the absolute value of the coordinates to get rid of that negative. shiftedCoords = abs(shiftedCoords); Now, let's edit our previous texture sampling code. float red = texture(iChannel0, normalizedCoords + (shiftedCoords * redOffset)).r; float green = texture(iChannel0, normalizedCoords + (shiftedCoords * greenOffset)).g; vec2 blueAlpha = texture(iChannel0, normalizedCoords + (shiftedCoords * blueOffset)).ba; So you see, the values range from 0.5 at the bottom left, to 0.5 at the top right. This means that in the center, the values are 0.0, or close to it. We're effectively reducing our offset by how close it is to the center. This means that the effect will only really be visible around the edges, which is exactly what we want. However, it's probably not going to be that visible, as we've effectively halved it, seeing how we're multiplying by at most, 0.5. So we can modify our absolute value line to increase it. shiftedCoords = abs(shiftedCoords) * 2.0; Doubling it brings it back to the original strength, but you can increase this or decrease it however you want to tweak the strength. Full Program const float STRENGTH = 2.0; void mainImage( out vec4 fragColor, in vec2 fragCoord ) { vec2 normalizedCoords = fragCoord/iResolution.xy; vec2 redOffset = vec2(0.001, 0.002); vec2 greenOffset = vec2(-0.002, 0.001); vec2 blueOffset = vec2(0.003, 0.002); vec2 shiftedCoords = normalizedCoords - 0.5; shiftedCoords = abs(shiftedCoords) * STRENGTH; float red = texture(iChannel0, normalizedCoords + (shiftedCoords * redOffset)).r; float green = texture(iChannel0, normalizedCoords + (shiftedCoords * greenOffset)).g; vec2 blueAlpha = texture(iChannel0, normalizedCoords + (shiftedCoords * blueOffset)).ba; fragColor = vec4(red, green, blueAlpha); }","title":"Chromatic Aberration"},{"location":"articles/post/ChromaticAberration/#chromatic-aberration","text":"Chromatic Aberration is an effect commonly observed in images, when the camera can't focus all color channels onto a point. This results in different colors being in slightly different positions. In shaders, this effect can be simulated by offsetting the position at which we sample each color channel. This is quite simple, but the value by which you offset needs to be quite small to look any good. Let's first assume a couple variables we have access to. fragCoord iResolution These are explained on the home page, under variables. Let's grab the normalized coordinates of our pixel. Since fragCoord ranges from 0 to the screen dimensions, we just need to divide by the screen dimensions. vec2 normalizedCoords = fragCoord/iResolution.xy; Now let's define some small offsets. vec2 redOffset = vec2(0.001, 0.002); vec2 greenOffset = vec2(-0.002, 0.001); vec2 blueOffset = vec2(0.003, 0.002); Now that we have some offsets, we can just sample our texture with them. Assuming we have a texture sampler called iChannel0 : float red = texture(iChannel0, normalizedCoords + redOffset).r; float green = texture(iChannel0, normalizedCoords + greenOffset).g; vec2 blueAlpha = texture(iChannel0, normalizedCoords + blueOffset).ba; Using swizzling , or accessing only a specific component of a vector, we can easily only get the value we need. Notice that for the last channel, I use a vector 2 instead of a float, because of course, we need to get the alpha channel as well. We'll just use the blue offset to sample the alpha channel. Now, we can join it all together. fragColor = vec4(red, green, blueAlpha);","title":"Chromatic Aberration"},{"location":"articles/post/ChromaticAberration/#edge-strengthing","text":"So, we've constructed our output color with the offset channels. This is often times enough, but realistically, you'll only see chromatic aberration near the very edges of images, and not so much the center. To make this effect more realistic, we can simulate that. We have the current normalized position in normalizedCoords . Now this ranges from 0 to 1, but with a bit of clever math we can get something cool. First, let's shift our coordinates over. vec2 shiftedCoords = normalizedCoords - 0.5; So now, the coordinates range from -0.5 to 0.5. We're close now, we just need to take the absolute value of the coordinates to get rid of that negative. shiftedCoords = abs(shiftedCoords); Now, let's edit our previous texture sampling code. float red = texture(iChannel0, normalizedCoords + (shiftedCoords * redOffset)).r; float green = texture(iChannel0, normalizedCoords + (shiftedCoords * greenOffset)).g; vec2 blueAlpha = texture(iChannel0, normalizedCoords + (shiftedCoords * blueOffset)).ba; So you see, the values range from 0.5 at the bottom left, to 0.5 at the top right. This means that in the center, the values are 0.0, or close to it. We're effectively reducing our offset by how close it is to the center. This means that the effect will only really be visible around the edges, which is exactly what we want. However, it's probably not going to be that visible, as we've effectively halved it, seeing how we're multiplying by at most, 0.5. So we can modify our absolute value line to increase it. shiftedCoords = abs(shiftedCoords) * 2.0; Doubling it brings it back to the original strength, but you can increase this or decrease it however you want to tweak the strength.","title":"Edge Strengthing"},{"location":"articles/post/ChromaticAberration/#full-program","text":"const float STRENGTH = 2.0; void mainImage( out vec4 fragColor, in vec2 fragCoord ) { vec2 normalizedCoords = fragCoord/iResolution.xy; vec2 redOffset = vec2(0.001, 0.002); vec2 greenOffset = vec2(-0.002, 0.001); vec2 blueOffset = vec2(0.003, 0.002); vec2 shiftedCoords = normalizedCoords - 0.5; shiftedCoords = abs(shiftedCoords) * STRENGTH; float red = texture(iChannel0, normalizedCoords + (shiftedCoords * redOffset)).r; float green = texture(iChannel0, normalizedCoords + (shiftedCoords * greenOffset)).g; vec2 blueAlpha = texture(iChannel0, normalizedCoords + (shiftedCoords * blueOffset)).ba; fragColor = vec4(red, green, blueAlpha); }","title":"Full Program"},{"location":"articles/post/GaussianBlur/","text":"Gaussian Blur // Coming soon","title":"Gaussian Blur"},{"location":"articles/post/GaussianBlur/#gaussian-blur","text":"// Coming soon","title":"Gaussian Blur"},{"location":"articles/post/Vignette/","text":"Vignette // Coming soon","title":"Vignette"},{"location":"articles/post/Vignette/#vignette","text":"// Coming soon","title":"Vignette"},{"location":"articles/vertex/","text":"Vertex Shaders Vertex shaders don't get a lot of recognition. They are integral to how we see graphics though, especially 3D graphics. Vertex shaders are responsible for running on vertices, or the points in our 3D model for example. They might handle converting world coordinates into screen-space coordinates, or perhaps procedural geometry deformation. They also pass a lot of data into fragment shaders, to enable them function properly (such as colors, or UVs).","title":"Index"},{"location":"articles/vertex/#vertex-shaders","text":"Vertex shaders don't get a lot of recognition. They are integral to how we see graphics though, especially 3D graphics. Vertex shaders are responsible for running on vertices, or the points in our 3D model for example. They might handle converting world coordinates into screen-space coordinates, or perhaps procedural geometry deformation. They also pass a lot of data into fragment shaders, to enable them function properly (such as colors, or UVs).","title":"Vertex Shaders"}]}